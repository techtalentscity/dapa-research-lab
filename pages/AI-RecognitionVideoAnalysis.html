<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DEPA Lab - Research</title>
    
    <!-- Fonts -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
    
    <!-- Styles - Note the ../ to go up one directory -->
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="../styles/pagestyles.css">
    
    <!-- Load components script first -->
    <script src="../script/include.js"></script>
    <!-- Other scripts -->
    <script defer src="../scripts.js"></script>
</head>

<!-- Header -->

<body>
    <div id="header-container"></div>

    <main>

<section class="page-banner">
    <div class="banner-content">
    </div>
</section>

<section class="academic-advisory">
    <div class="container">
        <h2 class="section-title">AI Models in Action Recognition Video Analysis</h2>
        
        <div class="content-single">
            <div class="content-card">
                <div class="card-icon">
                    <i class="fas fa-video"></i>
                </div>
                <h3>Research Overview</h3>
                <p>The CLAIRE (Cross-Referencing Labels, Actions, and Interactions for Robust Explanations) project aims to integrate YOLO detections and LLM vision to analyze video frames, cross-reference object/personâ€“person/person interactions, and generate detailed reports of the video frame's scene.</p>
                <p>This research explores both the benefits and restraints of utilizing AI models in action recognition video analysis. The project extends to CCTV footage as well as everyday video recordings, evaluating the strengths and shortcomings of AI-driven computer vision technologies in real-world applications.</p>
            </div>
        </div>
    </div>
</section>

        
    </main>

    <!-- Footer -->
   <div id="footer-container"></div>
</body>
</html>
